{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "qivobhrkkl9",
   "metadata": {},
   "source": [
    "# Pydantic + HuggingFace + Biopython í†µí•© ì‹¤ìŠµ\n",
    "\n",
    "**í•™ìŠµëª©í‘œ**: Biopythonìœ¼ë¡œ PubMedì—ì„œ ë…¼ë¬¸ ì´ˆë¡ì„ ê°€ì ¸ì™€ì„œ HuggingFace APIì™€ Pydanticì„ ì‚¬ìš©í•´ êµ¬ì¡°í™”ëœ ë¶„ì„ì„ ìˆ˜í–‰í•œë‹¤.\n",
    "\n",
    "**êµ¬ì„±ìš”ì†Œ**:\n",
    "- Biopython Entrez: PubMed ë°ì´í„° ìˆ˜ì§‘\n",
    "- Pydantic: ë°ì´í„° êµ¬ì¡° ì •ì˜ ë° ê²€ì¦\n",
    "- HuggingFace: LLM ê¸°ë°˜ í…ìŠ¤íŠ¸ ë¶„ì„\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58036c8",
   "metadata": {},
   "source": [
    "### Huggingface ì˜ˆì œ ì½”ë“œ\n",
    "[ì˜ˆì œ ë§í¬](https://huggingface.co/docs/inference-providers/guides/structured-output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ae9ddcd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"title\": \"Attention Is All You Need\", \"abstract_summary\": \"This paper demonstrates how the proposed Transformer model eliminates complex recurrent and convolutional neural networks while maintaining the encoder-decoder structure with attention mechanisms. The analysis showcases a new architecture based solely on attention mechanisms that outperforms traditional models in sequence transduction tasks.\"}\n"
     ]
    }
   ],
   "source": [
    "# https://huggingface.co/docs/inference-providers/guides/responses-api\n",
    "\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import InferenceClient\n",
    "from pydantic import BaseModel\n",
    "\n",
    "load_dotenv()\n",
    "# Initialize the client\n",
    "client = InferenceClient(\n",
    "    provider=\"cerebras\",  # or use \"auto\" for automatic selection\n",
    "    api_key=os.environ[\"HF_TOKEN\"],\n",
    ")\n",
    "\n",
    "# Example paper text (truncated for brevity)\n",
    "paper_text = \"\"\"\n",
    "Title: Attention Is All You Need\n",
    "\n",
    "Abstract: The dominant sequence transduction models are based on complex recurrent \n",
    "or convolutional neural networks that include an encoder and a decoder. The best \n",
    "performing models also connect the encoder and decoder through an attention mechanism. \n",
    "We propose a new simple network architecture, the Transformer, based solely on \n",
    "attention mechanisms, dispensing with recurrence and convolutions entirely...\n",
    "\"\"\"\n",
    "\n",
    "# Define the response format\n",
    "class PaperAnalysis(BaseModel):\n",
    "    title: str\n",
    "    abstract_summary: str\n",
    "\n",
    "# Convert the Pydantic model to a JSON Schema and wrap it in a dictionary\n",
    "response_format = {\n",
    "    \"type\": \"json_schema\",\n",
    "    \"json_schema\": {\n",
    "        \"name\": \"PaperAnalysis\",\n",
    "        \"schema\": PaperAnalysis.model_json_schema(),\n",
    "        \"strict\": True,\n",
    "    },\n",
    "}\n",
    "\n",
    "# Define your messages with a system prompt and a user prompt\n",
    "# The system prompt is a description of the task you want the model to perform\n",
    "# The user prompt is the input data you want to process\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\", \n",
    "        \"content\": \"Extract paper title and abstract summary.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\", \n",
    "        \"content\": paper_text\n",
    "    }\n",
    "]\n",
    "\n",
    "# Generate structured output using Qwen/Qwen3-32B model\n",
    "response = client.chat_completion(\n",
    "    messages=messages,\n",
    "    response_format=response_format,\n",
    "    model=\"Qwen/Qwen3-32B\",\n",
    ")\n",
    "\n",
    "# The response is guaranteed to match your schema\n",
    "structured_data = response.choices[0].message.content\n",
    "print(structured_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4146f920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrez Email: None\n",
      "HF API Key ì„¤ì •: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/insilicogen/kbiohealth_êµìœ¡/Python-Advanced/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ import\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from Bio import Entrez\n",
    "from huggingface_hub import InferenceClient\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "import json\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv()\n",
    "\n",
    "# HuggingFace í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”\n",
    "client = InferenceClient(\n",
    "    provider=\"cerebras\",\n",
    "    api_key=os.environ[\"HF_TOKEN\"],\n",
    ")\n",
    "\n",
    "print(f\"Entrez Email: {Entrez.email}\")\n",
    "print(f\"HF API Key ì„¤ì •: {bool(os.environ.get('HF_TOKEN'))}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b154239",
   "metadata": {},
   "source": [
    "### Pydantic ëª¨ë¸ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d79544f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PubMedArticle ìŠ¤í‚¤ë§ˆ: {'properties': {'pmid': {'title': 'Pmid', 'type': 'string'}, 'title': {'title': 'Title', 'type': 'string'}, 'abstract': {'title': 'Abstract', 'type': 'string'}, 'authors': {'items': {'type': 'string'}, 'title': 'Authors', 'type': 'array'}, 'journal': {'title': 'Journal', 'type': 'string'}, 'pub_year': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None, 'title': 'Pub Year'}}, 'required': ['pmid', 'title', 'abstract', 'authors', 'journal'], 'title': 'PubMedArticle', 'type': 'object'}\n",
      "\n",
      "PaperAnalysis ìŠ¤í‚¤ë§ˆ: {'description': 'ë…¼ë¬¸ ë¶„ì„ ê²°ê³¼ë¥¼ êµ¬ì¡°í™”í•˜ëŠ” ëª¨ë¸', 'properties': {'title': {'description': 'ë…¼ë¬¸ ì œëª©', 'title': 'Title', 'type': 'string'}, 'abstract_summary': {'description': 'ì´ˆë¡ ìš”ì•½ (2-3ë¬¸ì¥)', 'title': 'Abstract Summary', 'type': 'string'}, 'key_findings': {'description': 'ì£¼ìš” ë°œê²¬ì‚¬í•­ ëª©ë¡', 'items': {'type': 'string'}, 'title': 'Key Findings', 'type': 'array'}, 'methodology': {'description': 'ì‚¬ìš©ëœ ì—°êµ¬ ë°©ë²•ë¡ ', 'title': 'Methodology', 'type': 'string'}, 'significance': {'description': 'ì—°êµ¬ì˜ ì¤‘ìš”ì„± ë° ì˜í–¥', 'title': 'Significance', 'type': 'string'}, 'keywords': {'description': 'í•µì‹¬ í‚¤ì›Œë“œ 5ê°œ ì´í•˜', 'items': {'type': 'string'}, 'title': 'Keywords', 'type': 'array'}}, 'required': ['title', 'abstract_summary', 'key_findings', 'methodology', 'significance', 'keywords'], 'title': 'PaperAnalysis', 'type': 'object'}\n"
     ]
    }
   ],
   "source": [
    "# PubMed ë…¼ë¬¸ ì •ë³´ë¥¼ ë‹´ëŠ” Pydantic ëª¨ë¸\n",
    "class PubMedArticle(BaseModel):\n",
    "    pmid: str\n",
    "    title: str\n",
    "    abstract: str\n",
    "    authors: List[str]\n",
    "    journal: str\n",
    "    pub_year: Optional[str] = None\n",
    "\n",
    "# HuggingFaceë¡œ ë¶„ì„í•  êµ¬ì¡°í™”ëœ ì¶œë ¥ ëª¨ë¸\n",
    "class PaperAnalysis(BaseModel):\n",
    "    \"\"\"ë…¼ë¬¸ ë¶„ì„ ê²°ê³¼ë¥¼ êµ¬ì¡°í™”í•˜ëŠ” ëª¨ë¸\"\"\"\n",
    "    title: str = Field(description=\"ë…¼ë¬¸ ì œëª©\")\n",
    "    abstract_summary: str = Field(description=\"ì´ˆë¡ ìš”ì•½ (2-3ë¬¸ì¥)\")\n",
    "    key_findings: List[str] = Field(description=\"ì£¼ìš” ë°œê²¬ì‚¬í•­ ëª©ë¡\")\n",
    "    methodology: str = Field(description=\"ì‚¬ìš©ëœ ì—°êµ¬ ë°©ë²•ë¡ \")\n",
    "    significance: str = Field(description=\"ì—°êµ¬ì˜ ì¤‘ìš”ì„± ë° ì˜í–¥\")\n",
    "    keywords: List[str] = Field(description=\"í•µì‹¬ í‚¤ì›Œë“œ 5ê°œ ì´í•˜\")\n",
    "\n",
    "print(f\"PubMedArticle ìŠ¤í‚¤ë§ˆ: {PubMedArticle.model_json_schema()}\")\n",
    "print(f\"\\nPaperAnalysis ìŠ¤í‚¤ë§ˆ: {PaperAnalysis.model_json_schema()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9608864",
   "metadata": {},
   "source": [
    "### Biopythonìœ¼ë¡œ PubMed ë°ì´í„° ìˆ˜ì§‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "804d6129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\"machine learning\" AND bioinformatics AND 2024[DP]' ê²€ìƒ‰ ì¤‘...\n",
      "3ê°œ ë…¼ë¬¸ ë°œê²¬\n",
      "PMID 41031031: Rapid prediction of thermodynamically destabilizin...\n",
      "PMID 40995405: Persistent Laplacian-enhanced algorithm for scarce...\n",
      "PMID 40979399: Editorial: AI/ML in pharmacovigilance and pharmaco...\n",
      "\n",
      "ìˆ˜ì§‘ ì™„ë£Œ: 3ê°œ ë…¼ë¬¸\n",
      "\n",
      "1. PMID: 41031031\n",
      "   ì œëª©: Rapid prediction of thermodynamically destabilizing tyrosine phosphorylations in...\n",
      "   ì €ì: Jaie Woodard, Zhengqing Liu, Atena Malemir Chegini\n",
      "   ì €ë„: bioRxiv : the preprint server for biology\n",
      "   ì´ˆë¡ ê¸¸ì´: 1879 ë¬¸ì\n",
      "\n",
      "2. PMID: 40995405\n",
      "   ì œëª©: Persistent Laplacian-enhanced algorithm for scarcely labeled data classification...\n",
      "   ì €ì: Gokul Bhusal, Ekaterina Merkurjev, Guo-Wei Wei\n",
      "   ì €ë„: Machine learning\n",
      "   ì´ˆë¡ ê¸¸ì´: 1732 ë¬¸ì\n",
      "\n",
      "3. PMID: 40979399\n",
      "   ì œëª©: Editorial: AI/ML in pharmacovigilance and pharmacoepidemiology....\n",
      "   ì €ì: Wen Zou, Pantelis Natsiavas, Assaf Gottlieb\n",
      "   ì €ë„: Frontiers in drug safety and regulation\n",
      "   ì´ˆë¡ ê¸¸ì´: 0 ë¬¸ì\n"
     ]
    }
   ],
   "source": [
    "def fetch_pubmed_articles(search_term: str, max_results: int = 5) -> List[PubMedArticle]:\n",
    "    \"\"\"PubMedì—ì„œ ë…¼ë¬¸ì„ ê²€ìƒ‰í•˜ê³  PubMedArticle ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜\"\"\"\n",
    "    articles = []\n",
    "    \n",
    "    try:\n",
    "        # 1. PubMedì—ì„œ ê²€ìƒ‰\n",
    "        print(f\"'{search_term}' ê²€ìƒ‰ ì¤‘...\")\n",
    "        handle = Entrez.esearch(db=\"pubmed\", term=search_term, retmax=max_results)\n",
    "        search_results = Entrez.read(handle)\n",
    "        handle.close()\n",
    "        \n",
    "        pmids = search_results['IdList']\n",
    "        print(f\"{len(pmids)}ê°œ ë…¼ë¬¸ ë°œê²¬\")\n",
    "        \n",
    "        if not pmids:\n",
    "            return articles\n",
    "        \n",
    "        # 2. ê° ë…¼ë¬¸ì˜ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°\n",
    "        handle = Entrez.efetch(db=\"pubmed\", id=pmids, rettype=\"abstract\", retmode=\"xml\")\n",
    "        records = Entrez.read(handle)['PubmedArticle']\n",
    "        \n",
    "        for record in records:\n",
    "            try:\n",
    "                # ë…¼ë¬¸ ì •ë³´ ì¶”ì¶œ\n",
    "                article_info = record['MedlineCitation']['Article']\n",
    "                \n",
    "                # PMID\n",
    "                pmid = record['MedlineCitation']['PMID']\n",
    "                \n",
    "                # ì œëª©\n",
    "                title = article_info.get('ArticleTitle', 'No title')\n",
    "                \n",
    "                # ì´ˆë¡\n",
    "                abstract_text = \"\"\n",
    "                if 'Abstract' in article_info:\n",
    "                    abstract = article_info['Abstract']\n",
    "                    if 'AbstractText' in abstract:\n",
    "                        abstract_sections = abstract['AbstractText']\n",
    "                        if isinstance(abstract_sections, list):\n",
    "                            # êµ¬ì¡°í™”ëœ ì´ˆë¡\n",
    "                            abstract_parts = []\n",
    "                            for section in abstract_sections:\n",
    "                                if isinstance(section, dict):\n",
    "                                    label = section.get('@Label', '')\n",
    "                                    text = section.get('#text', str(section))\n",
    "                                    if label:\n",
    "                                        abstract_parts.append(f\"{label}: {text}\")\n",
    "                                    else:\n",
    "                                        abstract_parts.append(text)\n",
    "                                else:\n",
    "                                    abstract_parts.append(str(section))\n",
    "                            abstract_text = \" \".join(abstract_parts)\n",
    "                        else:\n",
    "                            abstract_text = str(abstract_sections)\n",
    "                \n",
    "                # ì €ìë“¤\n",
    "                authors = []\n",
    "                if 'AuthorList' in article_info:\n",
    "                    for author in article_info['AuthorList']:\n",
    "                        if isinstance(author, dict):\n",
    "                            if 'LastName' in author and 'ForeName' in author:\n",
    "                                authors.append(f\"{author['ForeName']} {author['LastName']}\")\n",
    "                            elif 'CollectiveName' in author:\n",
    "                                authors.append(author['CollectiveName'])\n",
    "                \n",
    "                # ì €ë„\n",
    "                journal = article_info.get('Journal', {}).get('Title', 'Unknown journal')\n",
    "                \n",
    "                # ë°œí–‰ì—°ë„\n",
    "                pub_year = None\n",
    "                if 'Journal' in article_info and 'JournalIssue' in article_info['Journal']:\n",
    "                    pub_date = article_info['Journal']['JournalIssue'].get('PubDate', {})\n",
    "                    pub_year = pub_date.get('Year')\n",
    "                \n",
    "                # PubMedArticle ê°ì²´ ìƒì„±\n",
    "                article = PubMedArticle(\n",
    "                    pmid=str(pmid),\n",
    "                    title=title,\n",
    "                    abstract=abstract_text,\n",
    "                    authors=authors[:5],  # ìµœëŒ€ 5ëª…ì˜ ì €ìë§Œ\n",
    "                    journal=journal,\n",
    "                    pub_year=pub_year\n",
    "                )\n",
    "                \n",
    "                articles.append(article)\n",
    "                print(f\"PMID {pmid}: {title[:50]}...\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"ë…¼ë¬¸ íŒŒì‹± ì˜¤ë¥˜: {e}\")\n",
    "                continue\n",
    "        \n",
    "        handle.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"PubMed ê²€ìƒ‰ ì˜¤ë¥˜: {e}\")\n",
    "    \n",
    "    return articles\n",
    "\n",
    "# ì‹¤ì œ ê²€ìƒ‰ ìˆ˜í–‰\n",
    "search_query = '\"machine learning\" AND bioinformatics AND 2024[DP]'\n",
    "pubmed_articles = fetch_pubmed_articles(search_query, max_results=3)\n",
    "\n",
    "print(f\"\\nìˆ˜ì§‘ ì™„ë£Œ: {len(pubmed_articles)}ê°œ ë…¼ë¬¸\")\n",
    "for i, article in enumerate(pubmed_articles):\n",
    "    print(f\"\\n{i+1}. PMID: {article.pmid}\")\n",
    "    print(f\"   ì œëª©: {article.title[:80]}...\")\n",
    "    print(f\"   ì €ì: {', '.join(article.authors[:3])}\")\n",
    "    print(f\"   ì €ë„: {article.journal}\")\n",
    "    print(f\"   ì´ˆë¡ ê¸¸ì´: {len(article.abstract)} ë¬¸ì\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32eba13d",
   "metadata": {},
   "source": [
    "### HuggingFaceë¡œ êµ¬ì¡°í™”ëœ ë…¼ë¬¸ ë¶„ì„\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f76d164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ë¶„ì„í•  ë…¼ë¬¸: Rapid prediction of thermodynamically destabilizing tyrosine...\n",
      "ì´ˆë¡ ë¯¸ë¦¬ë³´ê¸°: Tyrosine phosphorylations are a prominent characteristic of numerous cancers, necessitating the use of computational tools to comprehensively analyze phosphoproteomes and identify potentially (dys)fun...\n",
      "\n",
      "ğŸ¤– PMID 41031031 ë¶„ì„ ì¤‘...\n",
      "ë¶„ì„ ì™„ë£Œ: Rapid prediction of thermodynamically destabilizin...\n",
      "\n",
      "=== ë¶„ì„ ê²°ê³¼ ===\n",
      "ì œëª©: Rapid prediction of thermodynamically destabilizing tyrosine phosphorylations in cancers\n",
      "\n",
      "ìš”ì•½: ì´ ë…¼ë¬¸ì€ íƒ€ì´ë¡œì‹  ì¸ì‚°í™”ì˜ ì—´ì—­í•™ì  ì•ˆì •ë„ ê°ì†Œë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë°˜ ë°©ë²•ì„ ì œì•ˆí•œë‹¤. AlphaFold2 ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì´ìš©í•´ 384,857ê°œì˜ íƒ€ì´ë¡œì‹  residueë¥¼ ë¶„ì„í•˜ê³ , 600ê°œ ì´ìƒì˜ ê³ ìœ  ì¸ì‚°í™” ìœ í˜•ì„ í¬í•¨í•œ ë‹¤ì¢…ì–‘ ë°ì´í„°ë¥¼ ì ìš©í•˜ì—¬ ìê°€ì–µì œ ë˜ëŠ” í™œì„±í™” êµ¬ì¡° ë³€í™”ì™€ ì—°ê´€ëœ ì¸ì‚°í™”ë¥¼ ì˜ˆì¸¡í•˜ì˜€ë‹¤. ìƒë¬¼í•™ì  ê²½ë¡œì™€ ë„¤íŠ¸ì›Œí¬ ì¤‘ì‹¬ì„±ê³¼ì˜ ìƒê´€ê´€ê³„ë„ ë°í˜”ë‹¤.\n",
      "\n",
      "ì£¼ìš” ë°œê²¬ì‚¬í•­:\n",
      "  1. pKm (ì¸ì‚°ëª¨ì´í…Œí¬ ë¸íƒ€-ë¸íƒ€-G) ì˜ˆì¸¡ ëª¨ë¸ì˜ ì‹¤í—˜ì  ìƒê´€ê³„ìˆ˜ R=0.71 ë‹¬ì„±\n",
      "  2. ìê°€ì–µì œ ì˜¨ì½”ì  ì˜ ì¸ì‚°í™” ìƒíƒœ ì˜ˆì¸¡ AUC 0.85\n",
      "  3. í™”í•™ì /ì‚°í™”ì  ìŠ¤íŠ¸ë ˆìŠ¤ ê²½ë¡œì—ì„œ ìµœìƒìœ„ ì¸ì‚°í™” ë‹¨ë°±ì§ˆì˜ í’ë¶€í™”\n",
      "  4. ëŒ€ì‚¬ ë‹¨ë°±ì§ˆì—ì„œ ë„¤íŠ¸ì›Œí¬ ì¤‘ì‹¬ì„± ë‚®ì€ ë‹¨ë°±ì§ˆì˜ ì¸ì‚°í™” ì†Œë©¸ ê²½í–¥ (p=0.005)\n",
      "  5. ì¢…ì–‘ ì¬ë°œ ì¸ì‚°í™” ì¤‘ 58%ê°€ 1 kcal/mol ê¸°ì¤€ì—ì„œ ë¶ˆì•ˆì •í™”\n",
      "\n",
      "ë°©ë²•ë¡ : ê·¹ë‹¨ì  ê·¸ë¼ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ… ë¨¸ì‹ ëŸ¬ë‹ ì ‘ê·¼ë²•ì„ ì‚¬ìš©í•˜ì—¬ êµ¬ì¡°ì  íŠ¹ì„±ê³¼ íšŒë¡œ ìœ„ìƒ ë³‘ë ¬ ê´€ê³„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¸ì‚°í™” ìœ ë„ ë¶ˆì•ˆì •í™”ë¥¼ ì˜ˆì¸¡. AlphaFold2 ë°ì´í„°ë² ì´ìŠ¤ë¥¼ í™œìš©í•œ ëŒ€ê·œëª¨ íƒ€ì´ë¡œì‹  residue ë¶„ì„ ë° 11ì¢… ì¢…ì–‘ì˜ ì¸ì‚°í™” ë°ì´í„°ì…‹ ì ìš©.\n",
      "\n",
      "ì¤‘ìš”ì„±: ì•”ì—ì„œì˜ ì¸ì‚°í™” ì¡°ì ˆ ë©”ì»¤ë‹ˆì¦˜ ì´í•´ë¥¼ ê°€ì†í™”í•˜ê³ , ìê°€ì–µì œ ë‹¨ë°±ì§ˆì˜ í™œì„±í™” ê²½ë¡œë¥¼ ê·œëª…í•˜ì—¬ ì•½ë¬¼ ê°œë°œ ê¸°ë°˜ì„ ì œê³µ. ëŒ€ê·œëª¨ ì¸ì‚°í™” ë³€ì´ ë° ë¶ˆì•ˆì •í™” ë‹¨ë°±ì§ˆì˜ ì‹ ì†í•œ ìŠ¤í¬ë¦¬ë‹ ê°€ëŠ¥ì„±ì„ ì œì‹œ.\n",
      "\n",
      "í‚¤ì›Œë“œ: ë¨¸ì‹ ëŸ¬ë‹, íƒ€ì´ë¡œì‹  ì¸ì‚°í™”, ì—´ì—­í•™ì  ì•ˆì •ë„, ì•”, ì¸ì‚°í™” ë‹¨ë°±ì§ˆ\n"
     ]
    }
   ],
   "source": [
    "def analyze_paper_with_hf(article: PubMedArticle) -> PaperAnalysis:\n",
    "    \"\"\"HuggingFace APIë¥¼ ì‚¬ìš©í•´ ë…¼ë¬¸ì„ êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ë¶„ì„\"\"\"\n",
    "    \n",
    "    # Pydantic ëª¨ë¸ì„ JSON Schemaë¡œ ë³€í™˜\n",
    "    response_format = {\n",
    "        \"type\": \"json_schema\",\n",
    "        \"json_schema\": {\n",
    "            \"name\": \"PaperAnalysis\",\n",
    "            \"schema\": PaperAnalysis.model_json_schema(),\n",
    "            \"strict\": True,\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    # ë…¼ë¬¸ í…ìŠ¤íŠ¸ ì¤€ë¹„\n",
    "    paper_text = f\"\"\"\n",
    "    Title: {article.title}\n",
    "    \n",
    "    Authors: {', '.join(article.authors)}\n",
    "    \n",
    "    Journal: {article.journal} ({article.pub_year})\n",
    "    \n",
    "    Abstract: {article.abstract}\n",
    "    \"\"\"\n",
    "    \n",
    "    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì™€ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ì •ì˜\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"\"\"\n",
    "            ë‹¹ì‹ ì€ ìƒë¬¼ì •ë³´í•™ ë° ê¸°ê³„í•™ìŠµ ë¶„ì•¼ì˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. \n",
    "            ì£¼ì–´ì§„ ë…¼ë¬¸ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ í•­ëª©ë“¤ì„ ì¶”ì¶œí•˜ì„¸ìš”:\n",
    "            \n",
    "            1. ë…¼ë¬¸ ì œëª© (ì •í™•íˆ)\n",
    "            2. ì´ˆë¡ ìš”ì•½ (2-3ë¬¸ì¥ìœ¼ë¡œ í•µì‹¬ ë‚´ìš©)\n",
    "            3. ì£¼ìš” ë°œê²¬ì‚¬í•­ (êµ¬ì²´ì ì¸ ê²°ê³¼ë“¤)\n",
    "            4. ì—°êµ¬ ë°©ë²•ë¡  (ì‚¬ìš©ëœ ê¸°ë²•ì´ë‚˜ ì ‘ê·¼ë²•)\n",
    "            5. ì—°êµ¬ì˜ ì¤‘ìš”ì„± ë° ì˜í–¥\n",
    "            6. í•µì‹¬ í‚¤ì›Œë“œ (5ê°œ ì´í•˜)\n",
    "            \n",
    "            ëª¨ë“  ì‘ë‹µì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ê³ , êµ¬ì¡°í™”ëœ JSON í˜•íƒœë¡œ ë°˜í™˜í•˜ì„¸ìš”.\n",
    "            \"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": paper_text\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        # HuggingFace API í˜¸ì¶œ\n",
    "        print(f\"PMID {article.pmid} ë¶„ì„ ì¤‘...\")\n",
    "        response = client.chat_completion(\n",
    "            messages=messages,\n",
    "            response_format=response_format,\n",
    "            model=\"Qwen/Qwen3-32B\",\n",
    "            max_tokens=3000,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        # JSON ì‘ë‹µ íŒŒì‹±\n",
    "        structured_output = response.choices[0].message.content\n",
    "        analysis_data = json.loads(structured_output)\n",
    "        # Pydantic ëª¨ë¸ë¡œ ê²€ì¦ ë° ë³€í™˜\n",
    "        analysis = PaperAnalysis(**analysis_data)\n",
    "        \n",
    "        print(f\"ë¶„ì„ ì™„ë£Œ: {analysis.title[:50]}...\")\n",
    "        return analysis\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ë¶„ì„ ì˜¤ë¥˜: {e}\")\n",
    "        # ê¸°ë³¸ê°’ ë°˜í™˜\n",
    "        return PaperAnalysis(\n",
    "            title=article.title,\n",
    "            abstract_summary=\"ë¶„ì„ ì‹¤íŒ¨\",\n",
    "            key_findings=[\"ë¶„ì„ì„ ì™„ë£Œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤\"],\n",
    "            methodology=\"ì•Œ ìˆ˜ ì—†ìŒ\",\n",
    "            significance=\"ë¶„ì„ ì‹¤íŒ¨\",\n",
    "            keywords=[\"ì˜¤ë¥˜\"]\n",
    "        )\n",
    "\n",
    "# ì²« ë²ˆì§¸ ë…¼ë¬¸ ë¶„ì„\n",
    "if pubmed_articles:\n",
    "    first_article = pubmed_articles[0]\n",
    "    print(f\"\\në¶„ì„í•  ë…¼ë¬¸: {first_article.title[:60]}...\")\n",
    "    print(f\"ì´ˆë¡ ë¯¸ë¦¬ë³´ê¸°: {first_article.abstract[:200]}...\\n\")\n",
    "    \n",
    "    analysis_result = analyze_paper_with_hf(first_article)\n",
    "    \n",
    "    print(\"\\n=== ë¶„ì„ ê²°ê³¼ ===\")\n",
    "    print(f\"ì œëª©: {analysis_result.title}\")\n",
    "    print(f\"\\nìš”ì•½: {analysis_result.abstract_summary}\")\n",
    "    print(f\"\\nì£¼ìš” ë°œê²¬ì‚¬í•­:\")\n",
    "    for i, finding in enumerate(analysis_result.key_findings, 1):\n",
    "        print(f\"  {i}. {finding}\")\n",
    "    print(f\"\\në°©ë²•ë¡ : {analysis_result.methodology}\")\n",
    "    print(f\"\\nì¤‘ìš”ì„±: {analysis_result.significance}\")\n",
    "    print(f\"\\ní‚¤ì›Œë“œ: {', '.join(analysis_result.keywords)}\")\n",
    "else:\n",
    "    print(\"ë¶„ì„í•  ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eed2a408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"title\": \"Rapid prediction of thermodynamically destabilizing tyrosine phosphorylations in cancers\",\n",
      "  \"abstract_summary\": \"ì´ ë…¼ë¬¸ì€ íƒ€ì´ë¡œì‹  ì¸ì‚°í™”ì˜ ì—´ì—­í•™ì  ì•ˆì •ë„ ê°ì†Œë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë°˜ ë°©ë²•ì„ ì œì•ˆí•œë‹¤. AlphaFold2 ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì´ìš©í•´ 384,857ê°œì˜ íƒ€ì´ë¡œì‹  residueë¥¼ ë¶„ì„í•˜ê³ , 600ê°œ ì´ìƒì˜ ê³ ìœ  ì¸ì‚°í™” ìœ í˜•ì„ í¬í•¨í•œ ë‹¤ì¢…ì–‘ ë°ì´í„°ë¥¼ ì ìš©í•˜ì—¬ ìê°€ì–µì œ ë˜ëŠ” í™œì„±í™” êµ¬ì¡° ë³€í™”ì™€ ì—°ê´€ëœ ì¸ì‚°í™”ë¥¼ ì˜ˆì¸¡í•˜ì˜€ë‹¤. ìƒë¬¼í•™ì  ê²½ë¡œì™€ ë„¤íŠ¸ì›Œí¬ ì¤‘ì‹¬ì„±ê³¼ì˜ ìƒê´€ê´€ê³„ë„ ë°í˜”ë‹¤.\",\n",
      "  \"key_findings\": [\n",
      "    \"pKm (ì¸ì‚°ëª¨ì´í…Œí¬ ë¸íƒ€-ë¸íƒ€-G) ì˜ˆì¸¡ ëª¨ë¸ì˜ ì‹¤í—˜ì  ìƒê´€ê³„ìˆ˜ R=0.71 ë‹¬ì„±\",\n",
      "    \"ìê°€ì–µì œ ì˜¨ì½”ì  ì˜ ì¸ì‚°í™” ìƒíƒœ ì˜ˆì¸¡ AUC 0.85\",\n",
      "    \"í™”í•™ì /ì‚°í™”ì  ìŠ¤íŠ¸ë ˆìŠ¤ ê²½ë¡œì—ì„œ ìµœìƒìœ„ ì¸ì‚°í™” ë‹¨ë°±ì§ˆì˜ í’ë¶€í™”\",\n",
      "    \"ëŒ€ì‚¬ ë‹¨ë°±ì§ˆì—ì„œ ë„¤íŠ¸ì›Œí¬ ì¤‘ì‹¬ì„± ë‚®ì€ ë‹¨ë°±ì§ˆì˜ ì¸ì‚°í™” ì†Œë©¸ ê²½í–¥ (p=0.005)\",\n",
      "    \"ì¢…ì–‘ ì¬ë°œ ì¸ì‚°í™” ì¤‘ 58%ê°€ 1 kcal/mol ê¸°ì¤€ì—ì„œ ë¶ˆì•ˆì •í™”\"\n",
      "  ],\n",
      "  \"methodology\": \"ê·¹ë‹¨ì  ê·¸ë¼ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ… ë¨¸ì‹ ëŸ¬ë‹ ì ‘ê·¼ë²•ì„ ì‚¬ìš©í•˜ì—¬ êµ¬ì¡°ì  íŠ¹ì„±ê³¼ íšŒë¡œ ìœ„ìƒ ë³‘ë ¬ ê´€ê³„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¸ì‚°í™” ìœ ë„ ë¶ˆì•ˆì •í™”ë¥¼ ì˜ˆì¸¡. AlphaFold2 ë°ì´í„°ë² ì´ìŠ¤ë¥¼ í™œìš©í•œ ëŒ€ê·œëª¨ íƒ€ì´ë¡œì‹  residue ë¶„ì„ ë° 11ì¢… ì¢…ì–‘ì˜ ì¸ì‚°í™” ë°ì´í„°ì…‹ ì ìš©.\",\n",
      "  \"significance\": \"ì•”ì—ì„œì˜ ì¸ì‚°í™” ì¡°ì ˆ ë©”ì»¤ë‹ˆì¦˜ ì´í•´ë¥¼ ê°€ì†í™”í•˜ê³ , ìê°€ì–µì œ ë‹¨ë°±ì§ˆì˜ í™œì„±í™” ê²½ë¡œë¥¼ ê·œëª…í•˜ì—¬ ì•½ë¬¼ ê°œë°œ ê¸°ë°˜ì„ ì œê³µ. ëŒ€ê·œëª¨ ì¸ì‚°í™” ë³€ì´ ë° ë¶ˆì•ˆì •í™” ë‹¨ë°±ì§ˆì˜ ì‹ ì†í•œ ìŠ¤í¬ë¦¬ë‹ ê°€ëŠ¥ì„±ì„ ì œì‹œ.\",\n",
      "  \"keywords\": [\n",
      "    \"ë¨¸ì‹ ëŸ¬ë‹\",\n",
      "    \"íƒ€ì´ë¡œì‹  ì¸ì‚°í™”\",\n",
      "    \"ì—´ì—­í•™ì  ì•ˆì •ë„\",\n",
      "    \"ì•”\",\n",
      "    \"ì¸ì‚°í™” ë‹¨ë°±ì§ˆ\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(analysis_result.model_dump_json(indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d69057",
   "metadata": {},
   "source": [
    "## ğŸ¤—ìˆ˜ê³  ë§ìœ¼ì…¨ìŠµë‹ˆë‹¤ğŸ¤—"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
